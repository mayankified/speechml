{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f31d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happyness\n",
      "neutral\n",
      "anger\n",
      "happyness\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "happyness\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "disgust\n",
      "neutral\n",
      "neutral\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "disgust\n",
      "happyness\n",
      "neutral\n",
      "anger\n",
      "disgust\n",
      "disgust\n",
      "boredom\n",
      "anger\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "disgust\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "disgust\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "disgust\n",
      "neutral\n",
      "anger\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "anger\n",
      "disgust\n",
      "happyness\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "sadness\n",
      "anger\n",
      "disgust\n",
      "neutral\n",
      "anger\n",
      "fear\n",
      "neutral\n",
      "anger\n",
      "fear\n",
      "neutral\n",
      "anger\n",
      "fear\n",
      "happyness\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "happyness\n",
      "neutral\n",
      "anger\n",
      "anger\n",
      "fear\n",
      "boredom\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "fear\n",
      "boredom\n",
      "sadness\n",
      "anger\n",
      "fear\n",
      "disgust\n",
      "happyness\n",
      "boredom\n",
      "fear\n",
      "boredom\n",
      "neutral\n",
      "anger\n",
      "boredom\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as pld\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vmdpy import VMD\n",
    "import EntropyHub as eh\n",
    "from pyentrp import entropy as ent\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "\n",
    "def energy(signal,frame_length,hop_length):\n",
    "    energy=[]\n",
    "    for i in range(0,len(signal),hop_length):\n",
    "        rms_current_frame_energy=np.sum(signal[i:i+frame_length]**2)\n",
    "        energy.append(rms_current_frame_energy)\n",
    "    total_energy=np.array(energy)\n",
    "    total_energy_mean=np.mean(total_energy)\n",
    "    return total_energy_mean\n",
    "\n",
    "\n",
    "def rms(signal,frame_length,hop_length):\n",
    "    for i in range(0,len(signal),hop_length):\n",
    "        rms_energy_current_frame=np.sqrt(np.sum(signal[i:i+frame_length]**2)/frame_length)\n",
    "    return rms_energy_current_frame\n",
    "\n",
    "#DataFlair - Emotions in the EMODB dataset\n",
    "emotions={\n",
    "  'W':'anger',\n",
    "  'L':'boredom',\n",
    "  'E':'disgust',\n",
    "  'A':'fear',\n",
    "  'F':'happyness',\n",
    "  'T':'sadness',\n",
    "  'N':'neutral',\n",
    "  }\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "sr=16000\n",
    "q = signal.windows.hanning(800)\n",
    "\n",
    "\n",
    "alpha = 5000      # moderate bandwidth constraint\n",
    "tau = 0           # noise-tolerance (no strict fidelity enforcement)\n",
    "K = 3             # 3 modes\n",
    "DC = 0             # no DC part imposed\n",
    "init = 1           # initialize omegas uniformly\n",
    "tol = 1e-7\n",
    "\n",
    "# load the data set\n",
    "for dirname, _, filenames in os.walk('D:/database/emodb_database/wav'):\n",
    "    for filename in filenames:\n",
    "        paths = os.path.join(dirname, filename)\n",
    "        label = filename.split('.')[-2]  # it will split based on _ and extract the last word or first from right side\n",
    "        label=emotions[label[-2]]\n",
    "        print(label)\n",
    "        signal, sample_rate = librosa.load(paths,sr=16000)\n",
    "        signal = librosa.effects.preemphasis(signal, coef=0.97, zi=None, return_zf=False)\n",
    "        # normalize the audio signal\n",
    "        signal = librosa.util.normalize(signal)\n",
    "\n",
    "        # total energy of the audio signal\n",
    "        total_energy = energy(signal, frame_length=800, hop_length=400)\n",
    "        # print(total_energy)\n",
    "        hop_length = 400\n",
    "        frame_length = 800\n",
    "\n",
    "        feature=[]\n",
    "        for i in range(0, len(signal), hop_length):\n",
    "            current_frame = signal[i:i + frame_length]\n",
    "            current_frame1 = np.zeros(800)\n",
    "            for index in range(len(current_frame)):\n",
    "                current_frame1[index] = current_frame[index] * q[index]\n",
    "            u, u_hat, omega = VMD(current_frame1, alpha, tau, K, DC, init, tol) #variational mode decomposition\n",
    "            data=[]\n",
    "            for i in range(len(u)):\n",
    "                MFCCs = librosa.feature.mfcc(y=u[i], n_fft=800, hop_length=400, sr=sr, n_mfcc=30).T\n",
    "                MFCCs_mean = np.mean(MFCCs, axis=0)  # 20 in size\n",
    "                for i1 in MFCCs_mean:\n",
    "                    data.append(i1) # total 60 coefficient appended\n",
    "\n",
    "#           \n",
    "            feature.append(data)\n",
    "            # print(len(feature))\n",
    "        feature=np.array(feature)\n",
    "        # print(feature.shape)\n",
    "        # print(type(feature))\n",
    "        feature_avg=np.mean(feature,axis=0)\n",
    "        # print(feature_avg.shape)\n",
    "        # print(type(feature_avg))\n",
    "        feature_avg=feature_avg.tolist()\n",
    "        # print(feature_avg.shape)\n",
    "        # print(type(feature_avg))\n",
    "        final_data = []\n",
    "        final_data.append(filename)\n",
    "        final_data.extend(feature_avg)\n",
    "        final_data.append(label)\n",
    "        with open('D:/database/emodb_database/emodb_related/VARIATIONAL_MODE_DECOMPOSITION/vmd_mfcc_90_coefficient_k_3_myank.csv', \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(final_data)\n",
    "print('data set is loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d283b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
